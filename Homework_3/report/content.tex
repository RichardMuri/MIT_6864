\chapter*{Part One: Hidden Markov Models}
\addcontentsline{toc}{chapter}{Part One}

Note: I collaborated with Vivienne Zhang and Justin Yao.

The first part of the assignment was to implement a Hidden Markov Model (HMM). HMMs model

\subsection*{Computation Problem A}

The most obvious way to represent the four example observations is a series of disconnected two state Moore state machines (see Figure \ref{moore}). There are four patterns alternating between emitted words, thus four state machines. Each state has a 100\% probability of emitting a particular word. The separate machines are only connected by the initial state distribution $\pi$. I chose to represent my machine with a uniform initial distribution, but any $\pi$ where all $\pi_i$ are non-zero probabilities that sum to $1$ works.

\begin{figure}[h]

    \centering
    \begin{tikzpicture}[->, >=stealth', auto, semithick, node distance=3cm]
        \tikzstyle{every state}=[fill=white,draw=black,thick,text=black,scale=1]
        \node[state]    (A)                     {Word $0$};
        \node[state]    (B)[right of=A]   {Word $2$};

        \path
        (A) edge[bend left]			node{$1$}	(B)
        (B) edge[bend left,above]	node{$1$}	(A);
    \end{tikzpicture}
    \caption{A two state Moore machine (or Markov chain) where the emission probability is 1 for every state. The states are named after the emitted word. }
    \label{moore}
\end{figure}

My state transition matrix $\bm{A}$, emission matrix $\bm{B}$, and initial state distribution $\pi$ are as follows:

\noindent
\begin{multicols}{3}

    \begin{equation*}
        A = \begin{bmatrix}
            0 & 1 & 0 & 0 & 0 & 0 & 0 & 0 \\
            1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
            0 & 0 & 0 & 1 & 0 & 0 & 0 & 0 \\
            0 & 0 & 1 & 0 & 0 & 0 & 0 & 0 \\
            0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\
            0 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\
            0 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\
            0 & 0 & 0 & 0 & 1 & 0 & 0 & 0
        \end{bmatrix}
    \end{equation*}
    \break
    \noindent
    \begin{equation*}
        B = \begin{bmatrix}
            1 & 0 & 0 & 0 \\
            0 & 0 & 1 & 0 \\
            1 & 0 & 0 & 0 \\
            0 & 0 & 0 & 1 \\
            0 & 1 & 0 & 0 \\
            0 & 0 & 1 & 0 \\
            0 & 1 & 0 & 0 \\
            0 & 0 & 0 & 1
        \end{bmatrix}
    \end{equation*}
    \break
    \noindent
    \begin{equation*}
        \pi = \begin{bmatrix}
            0.25 & 0.25 & 0.25 & 0.25
        \end{bmatrix}
    \end{equation*}
\end{multicols}


\subsection*{Experimental Problem B}

It's difficult to exactly reason about what the hidden states directly encode. A naturally intuitive way to approach representing a sentence is to represent word 0 as state 0, word 1 as state 1 and so on, however we can start in any state depending on the initial distribution, and middle states may be difficult to distinguish given the vast number of words that can appear in the middle of a sentence.

Another approach would be to model parts of speech as a state, and develop probabilities of transitioning such as from an adjective to the noun it modifies. Unfortunately it's not evident in my results this kind of relationship is modelled.

\begin{center}

    \begin{tabular}{ |r|r| }

        \hline
        \multicolumn{2}{|c|}{Two state HMM word probabilities} \\
        \hline
        State 0     & State 1                                  \\
        \hline
        <unk> 0.112 & i     0.061                              \\
        .     0.085 & ,     0.039                              \\
        the   0.044 & <unk> 0.038                              \\
        a     0.034 & to    0.036                              \\
        ,     0.030 & .     0.035                              \\
        and   0.027 & the   0.029                              \\
        br    0.025 & it    0.025                              \\
        of    0.025 & and   0.020                              \\
        in    0.015 & not   0.014                              \\
        is    0.013 & but   0.014                              \\
        \hline
    \end{tabular}
\end{center}

\begin{center}

    \begin{tabular}{ |r|r|r|r| }

        \hline
        \multicolumn{4}{|c|}{Ten state HMM word probabilities} \\
        \hline
        State 0     & State 1     & State 8     & State 9      \\
        \hline
        <unk> 0.352 & . 0.118     & <unk> 0.101 & <unk> 0.102  \\
        a 0.067     & and 0.107   & in 0.057    & to 0.058     \\
        in 0.0293   & the 0.104   & the 0.054   & . 0.036      \\
        and 0.027   & , 0.103     & a 0.041     & not 0.030    \\
        or 0.024    & a 0.037     & it 0.033    & for 0.024    \\
        to 0.016    & <unk> 0.022 & at 0.024    & they 0.023   \\
        , 0.015     & of 0.020    & that 0.023  & the 0.019    \\
        of 0.008    & that 0.017  & for 0.019   & good 0.018   \\
        all 0.006   & my 0.014    & my 0.017    & them 0.017   \\
        but 0.006   & when 0.014  & and 0.016   & br 0.017     \\
        \hline
    \end{tabular}
\end{center}

\subsection*{Experimental Problem C}

\begin{center}
    \begin{tabular}{|l|}
        \hline
        we one guess flaxseed because to customer ever flat the \\ \hline
        my figured a <unk> snack . sold , bit pieces            \\ \hline
        if has to the <unk> term <unk> it wouldn't the          \\ \hline
        i do if better buy the <unk> . , and                    \\ \hline
        i used best such beat to said there was <unk>           \\ \hline
        i believe my as <unk> a . as amazon and                 \\ \hline
        it money . the make on and so only happen               \\ \hline
        this the regularly them the by ! <unk> a not            \\ \hline
        <unk> out dog ! no <unk> about time a chance            \\ \hline
        i bought not in to better reviewer it of a              \\ \hline
    \end{tabular}
\end{center}

\subsection*{Theoretical Problem D}

\chapter*{Part Two: Trees}
\addcontentsline{toc}{chapter}{Part Two}

\subsection*{Theoretical Problem A}

\subsection*{Part A}
\subsubsection*{Experimental Problem A}
\subsubsection*{Experimental Problem B}
\subsubsection*{Experimental Problem C}

\subsection*{Part B}
\subsubsection*{Experimental Problem A}
\subsubsection*{Experimental Problem B}
\subsubsection*{Experimental Problem C}
\subsubsection*{Theoretical Problem D}

