{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "6864_hw2_fa21.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%%bash\r\n",
        "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit \r\n",
        "rm -rf MIT_6864\r\n",
        "git clone \\\r\n",
        "  --depth 1  \\\r\n",
        "  --filter=blob:none  \\\r\n",
        "  --no-checkout \\\r\n",
        "  https://github.com/RichardMuri/MIT_6864\r\n",
        "cd MIT_6864\r\n",
        "git checkout main -- Homework_2/reviews.csv Homework_2/lab_util.py ML_utilities.py"
      ],
      "outputs": [],
      "metadata": {
        "id": "FU7xWiY6TyWS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import sys\r\n",
        "sys.path.append(\"/content/MIT_6864\")\r\n",
        "sys.path.append(\"/content/MIT_6864/Homework_2\")\r\n",
        "\r\n",
        "import csv\r\n",
        "import itertools as it\r\n",
        "import numpy as np\r\n",
        "import sklearn.decomposition\r\n",
        "np.random.seed(0)\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "import lab_util\r\n",
        "import ML_utilities"
      ],
      "outputs": [],
      "metadata": {
        "id": "A0MHaHrdUACZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "\n",
        "In this notebook, you will find code scaffolding for the implementation portion of Homework 2. There are certain parts of the scaffolding marked with `# Your code here!` comments where you can fill in code to perform the specified tasks. After implementing the methods in this notebook, you will need to design and perform experiments to evaluate each method and respond to the questions in the Homework 2 handout (available on Canvas). You should be able to complete this assignment without changing any of the scaffolding code, just writing code to fill in the scaffolding and run experiments."
      ],
      "metadata": {
        "id": "cZ3MUj4iUf76"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "We're going to be working with a dataset of product reviews. The following cell loads the dataset and splits it into training, validation, and test sets."
      ],
      "metadata": {
        "id": "gG654Y9J3yHw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "data = []\r\n",
        "n_positive = 0\r\n",
        "n_disp = 0\r\n",
        "with open(\"/content/MIT_6864/Homework_2/reviews.csv\") as reader:\r\n",
        "  csvreader = csv.reader(reader)\r\n",
        "  next(csvreader)\r\n",
        "  for id, review, label in csvreader:\r\n",
        "    label = int(label)\r\n",
        "\r\n",
        "    # hacky class balancing\r\n",
        "    if label == 1:\r\n",
        "      if n_positive == 2000:\r\n",
        "        continue\r\n",
        "      n_positive += 1\r\n",
        "    if len(data) == 4000:\r\n",
        "      break\r\n",
        "\r\n",
        "    data.append((review, label))\r\n",
        "    \r\n",
        "    if n_disp > 5:\r\n",
        "      continue\r\n",
        "    n_disp += 1\r\n",
        "    print(\"review:\", review)\r\n",
        "    print(\"rating:\", label, \"(good)\" if label == 1 else \"(bad)\")\r\n",
        "    print()\r\n",
        "\r\n",
        "print(f\"Read {len(data)} total reviews.\")\r\n",
        "np.random.shuffle(data)\r\n",
        "reviews, labels = zip(*data)\r\n",
        "train_reviews = reviews[:3000]\r\n",
        "train_labels = labels[:3000]\r\n",
        "val_reviews = reviews[3000:3500]\r\n",
        "val_labels = labels[3000:3500]\r\n",
        "test_reviews = reviews[3500:]\r\n",
        "test_labels = labels[3500:]"
      ],
      "outputs": [],
      "metadata": {
        "id": "JwiX-Tc9V1xI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: word representations via matrix factorization\n",
        "\n",
        "First, we'll construct the term-document matrix (look at `/content/hw2/lab_util.py` in the file browser on the left if you want to see how this works)."
      ],
      "metadata": {
        "id": "twLHWqM6Z5xD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "vectorizer = lab_util.CountVectorizer()\n",
        "vectorizer.fit(train_reviews)\n",
        "td_matrix = vectorizer.transform(train_reviews).T\n",
        "print(f\"TD matrix is {td_matrix.shape[0]} x {td_matrix.shape[1]}\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "3WPt6Y7-Z_7P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, implement the function `learn_reps_lsa` that computes word representations via latent semantic analysis. The `sklearn.decomposition` or `np.linalg` packages may be useful."
      ],
      "metadata": {
        "id": "hd3-pw4XbD4B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import sklearn.decomposition\n",
        "def learn_reps_lsa(matrix, rep_size):\n",
        "    # `matrix` is a `|V| x n` matrix (usually a TD matrix), \n",
        "    # where `|V|` is the number of words in the vocabulary and `n`\n",
        "    # is the number of reviews in the (training) corpus.\n",
        "    # This function should return a `|V| x rep_size` matrix with each\n",
        "    # row corresponding to a word representation.\n",
        "\n",
        "    # Your code here!\n",
        "    raise NotImplementedError"
      ],
      "outputs": [],
      "metadata": {
        "id": "KASVs8KubeBE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sanity check 1\n",
        "The following cell contains a simple sanity check for your `learn_reps_lsa` implementation: it should print `True` if your `learn_reps_lsa` function is implemented equivalently to one of our solutions.  There are at least two reasonable ways to formulate these LSA word representations (whether you directly use the left singular vectors of `matrix` or scale them by the singular values), these correspond to the two possible representations in the sanity check below."
      ],
      "metadata": {
        "id": "0fxv02wO9LbS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "DEBUG_sc1_matrix = np.array([[1,0,0,2,1,3,5],\n",
        "                             [2,0,0,0,0,4,0],\n",
        "                             [0,3,4,1,8,6,6],\n",
        "                             [1,4,5,0,0,0,0]])\n",
        "\n",
        "DEBUG_reps = learn_reps_lsa(DEBUG_sc1_matrix, 3)\n",
        "DEBUG_gt1 = np.array([[ -4.92017554,  -2.85465774,   1.18575453],\n",
        "                      [ -2.14977584,  -1.19987977,   3.37221899],\n",
        "                      [-12.62664695,   0.10890093,  -1.32131745],\n",
        "                      [ -2.69216011,   5.66453534,   1.33728063]])\n",
        "DEBUG_gt2 = np.array([[-0.35188159, -0.44213061,  0.29358929],\n",
        "                      [-0.15374788, -0.18583789,  0.83495136],\n",
        "                      [-0.90303377,  0.01686662, -0.32715426],\n",
        "                      [-0.19253817,  0.87732566,  0.3311067 ]])\n",
        "\n",
        "print(np.allclose(np.abs(DEBUG_reps), np.abs(DEBUG_gt1)) or np.allclose(np.abs(DEBUG_reps), np.abs(DEBUG_gt2)))"
      ],
      "outputs": [],
      "metadata": {
        "id": "KsRlKB9q9Js-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at some representations:"
      ],
      "metadata": {
        "id": "SKWzRC0dclVK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "reps = learn_reps_lsa(td_matrix, 500)\n",
        "words = [\"good\", \"bad\", \"cookie\", \"jelly\", \"dog\", \"the\", \"4\"]\n",
        "show_tokens = [vectorizer.tokenizer.word_to_token[word] for word in words]\n",
        "lab_util.show_similar_words(vectorizer.tokenizer, reps, show_tokens)"
      ],
      "outputs": [],
      "metadata": {
        "id": "-Ad7RZkwceWw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've been operating on the raw count matrix, but in class we discussed several reweighting schemes aimed at making LSA representations more informative. \n",
        "\n",
        "Here, implement the TF-IDF transform and see how it affects learned representations. While it is okay (and in fact encouraged) to use vectorized numpy operations, you should refrain from using pre-implemented library functions for computing TF-IDF."
      ],
      "metadata": {
        "id": "LsOAGLB3iRjT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def transform_tfidf(matrix):\n",
        "    # `matrix` is a `|V| x |D|` TD matrix of raw counts, where `|V|` is the \n",
        "    # vocabulary size and `|D|` is the number of documents in the corpus. This\n",
        "    # function should return a version of `matrix` with the TF-IDF transform\n",
        "    # applied. Note: this function should be nondestructive: it should not\n",
        "    # modify the input; instead, it should return a new object.\n",
        "\n",
        "    # Your code here!\n",
        "    raise NotImplementedError"
      ],
      "outputs": [],
      "metadata": {
        "id": "1y3PmW-IgpqA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Sanity check 2\n",
        "The following cell should print `True` if your `transform_tfidf` function is implemented properly. (*Hint: in our implementation, we use the natural logarithm (base $e$) when computing inverse document frequency.*)"
      ],
      "metadata": {
        "id": "CnfIOUYjEZjw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "DEBUG_sc2_matrix = np.array([[3,1,0,3,0],\n",
        "                             [0,2,0,0,1],\n",
        "                             [7,8,2,0,1],\n",
        "                             [1,9,8,1,0]])\n",
        "DEBUG_gt = np.array([[1.53247687, 0.51082562, 0.        , 1.53247687, 0.        ],\n",
        "                     [0.        , 1.83258146, 0.        , 0.        , 0.91629073],\n",
        "                     [1.56200486, 1.78514841, 0.4462871 , 0.        , 0.22314355],\n",
        "                     [0.22314355, 2.00829196, 1.78514841, 0.22314355, 0.        ]])\n",
        "print(np.allclose(transform_tfidf(DEBUG_sc2_matrix), DEBUG_gt))"
      ],
      "outputs": [],
      "metadata": {
        "id": "KVtphNeDEj2W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How does TF-IDF normalization change the learned similarity function?\n"
      ],
      "metadata": {
        "id": "xOprgqzHi7bk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "td_matrix_tfidf = transform_tfidf(td_matrix)\n",
        "reps_tfidf = learn_reps_lsa(td_matrix_tfidf, 500)\n",
        "# reps_tfidf = learn_reps_lsa(td_matrix_tfidf, 100)\n",
        "lab_util.show_similar_words(vectorizer.tokenizer, reps_tfidf, show_tokens)"
      ],
      "outputs": [],
      "metadata": {
        "id": "SV5xKLYTi7LA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have some representations, let's see if we can do something useful with them.\n",
        "\n",
        "Below, implement a feature function that represents a document as the sum of its\n",
        "learned word embeddings.\n",
        "\n",
        "The remaining code trains a logistic regression model on a set of *labeled* reviews; we're interested in seeing how much representations learned from *unlabeled* reviews improve classification.\n",
        "\n",
        "(Note: the staff solutions for each of the three featurizers achieve accuracies of between .78 and .83 with the full training corpus (3000 examples).)"
      ],
      "metadata": {
        "id": "HO-NG4u1kG9z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import sklearn.linear_model\n",
        "\n",
        "def word_featurizer(xs):\n",
        "    # normalize\n",
        "    return xs / np.sqrt((xs ** 2).sum(axis=1, keepdims=True))\n",
        "\n",
        "def lsa_featurizer(xs):\n",
        "    # This function takes in a `|V| x |D|` TD matrix in which each row contains\n",
        "    # the word counts for the given review.\n",
        "    # It should return a matrix where each row contains the learned feature\n",
        "    # representation of each review (e.g. the sum of LSA word representations).\n",
        "    # (Hint: use TF-IDF LSA features, which should be a global variable after\n",
        "    # running the previous cell; no need to pass it in as an argument.)\n",
        "\n",
        "    feats = None  # Your code here!\n",
        "\n",
        "    # normalize\n",
        "    return feats / np.sqrt((feats ** 2).sum(axis=1, keepdims=True))\n",
        "\n",
        "# We've implemented the remainder of the training and evaluation pipeline,\n",
        "# so you likely won't need to modify the following four functions.\n",
        "def combo_featurizer(xs):\n",
        "    return np.concatenate((word_featurizer(xs), lsa_featurizer(xs)), axis=1)\n",
        "\n",
        "def train_model(featurizer, xs, ys):\n",
        "    xs_featurized = featurizer(xs)\n",
        "    model = sklearn.linear_model.LogisticRegression()\n",
        "    model.fit(xs_featurized, ys)\n",
        "    return model\n",
        "\n",
        "def eval_model(model, featurizer, xs, ys):\n",
        "    xs_featurized = featurizer(xs)\n",
        "    pred_ys = model.predict(xs_featurized)\n",
        "    return np.mean(pred_ys == ys)\n",
        "\n",
        "def training_experiment(name, featurizer, n_train):\n",
        "    print(f\"{name} features, {n_train} examples\")\n",
        "    train_xs = vectorizer.transform(train_reviews[:n_train])\n",
        "    train_ys = train_labels[:n_train]\n",
        "    test_xs = vectorizer.transform(test_reviews)\n",
        "    test_ys = test_labels\n",
        "    model = train_model(featurizer, train_xs, train_ys)\n",
        "    acc = eval_model(model, featurizer, test_xs, test_ys)\n",
        "    print(acc, '\\n')\n",
        "    return acc\n",
        "\n",
        "# The following four lines will run a training experiment with all 3k examples\n",
        "# in training set for each feature type. `training_experiment` may be useful to\n",
        "# you when performing experiments to answer questions in the handout.\n",
        "n_train = 3000\n",
        "training_experiment(\"word\", word_featurizer, n_train)\n",
        "training_experiment(\"lsa\", lsa_featurizer, n_train)\n",
        "training_experiment(\"combo\", combo_featurizer, n_train)\n",
        "print()"
      ],
      "outputs": [],
      "metadata": {
        "id": "6B08xvIFlee3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 1: Lab writeup**\n",
        "\n",
        "Part 1 of your lab report should discuss any implementation details that were important to filling out the code above, as well as your answers to the questions in Part 1 of the Homework 2 handout. Below, you can set up and perform experiments that answer these questions (include figures, plots, and tables in your write-up as you see fit)."
      ],
      "metadata": {
        "id": "rpXziVNrlfp2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiments for Part 1"
      ],
      "metadata": {
        "id": "L3WrzsHhC1I5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Your code here!"
      ],
      "outputs": [],
      "metadata": {
        "id": "aTVF9JdRNOsx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: word representations via language modeling\n",
        "\n",
        "In this section, we'll train a word embedding model with a word2vec-style objective rather than a matrix factorization objective. This requires a little more work; we've provided scaffolding for a PyTorch model implementation below.\n",
        "If you don't have much PyTorch experience, there are some tutorials [here](https://pytorch.org/tutorials/) which may be useful. You're also welcome to implement these experiments in any other framework of your choosing (note that we won't be able to provide debugging support if you use a different framework)."
      ],
      "metadata": {
        "id": "AxfunCYh5nmZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as torch_data\n",
        "\n",
        "class Word2VecModel(nn.Module):\n",
        "    # A torch module implementing a word2vec predictor. The `forward` function\n",
        "    # should take a batch of context word ids as input and predict the word \n",
        "    # in the middle of the context as output, as in the CBOW model from lecture.\n",
        "    # Hint: look at how padding is handled in lab_util.get_ngrams when\n",
        "    # initializing `ctx`: vocab_size is used as the padding token for contexts\n",
        "    # near the beginning and end of sequences. If you use an embedding module\n",
        "    # in your Word2Vec implementation, make sure to account for this extra\n",
        "    # padding token, and account for it with the `padding_idx` kwarg.\n",
        "\n",
        "    def __init__(self, vocab_size, embed_dim, , padding_idx=2006):\n",
        "        super().__init__()\n",
        "\n",
        "        # Your code here!\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def forward(self, context):\n",
        "        # Context is an `n_batch x vocab_size` matrix of integer word ids\n",
        "        # this function should return an `n_batch x vocab_size` matrix with\n",
        "        # element i, j being the (possibly log) probability of the middle word\n",
        "        # in context i being word j.\n",
        "\n",
        "        # Your code here!\n",
        "        raise NotImplementedError"
      ],
      "outputs": [],
      "metadata": {
        "id": "M1napibQ6aub"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def learn_reps_word2vec(corpus, window_size, rep_size, n_epochs, n_batch):\n",
        "    #This method takes in a corpus of training sentences. It returns a matrix of\n",
        "    # word embeddings with the same structure as used in the previous section of \n",
        "    # the assignment. (You can extract this matrix from the parameters of the \n",
        "    # Word2VecModel.)\n",
        "\n",
        "    tokenizer = lab_util.Tokenizer()\n",
        "    tokenizer.fit(corpus)\n",
        "    tokenized_corpus = tokenizer.tokenize(corpus)\n",
        "\n",
        "    ngrams = lab_util.get_ngrams(tokenized_corpus, window_size, pad_idx=2006)\n",
        "\n",
        "    device = torch.device('cuda')  # run on colab gpu\n",
        "    model = Word2VecModel(tokenizer.vocab_size, rep_size).to(device)\n",
        "    opt = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    loader = torch_data.DataLoader(ngrams, batch_size=n_batch, shuffle=True)\n",
        "\n",
        "    # What loss function should we use for Word2Vec?\n",
        "    loss_fn = None  # Your code here!\n",
        "\n",
        "    losses = []  # Potentially useful for debugging (loss should go down!)\n",
        "    for epoch in tqdm(range(n_epochs)):\n",
        "        epoch_loss = 0\n",
        "        for context, label in loader:\n",
        "            # As described above, `context` is a batch of context word ids, and\n",
        "            # `label` is a batch of predicted word labels.\n",
        "\n",
        "            # Here, perform a forward pass to compute predictions for the model.\n",
        "            # Your code here!\n",
        "            preds = None\n",
        "\n",
        "\n",
        "            # Now finish the backward pass and gradient update.\n",
        "            # Remember, you need to compute the loss, zero the gradients\n",
        "            # of the model parameters, perform the backward pass, and\n",
        "            # update the model parameters.\n",
        "            # Your code here!\n",
        "            loss = None\n",
        "\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "        losses.append(epoch_loss)\n",
        "\n",
        "    # Hint: you want to return a `vocab_size x embedding_size` numpy array\n",
        "    embedding_matrix = None  # Your code here!\n",
        "\n",
        "    return embedding_matrix"
      ],
      "outputs": [],
      "metadata": {
        "id": "ePgZlityuWr3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Use the function you just wrote to learn Word2Vec embeddings:\n",
        "reps_word2vec = learn_reps_word2vec(train_reviews, 2, 500, 10, 100)"
      ],
      "outputs": [],
      "metadata": {
        "id": "aaUy1cNuB3W1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After training the embeddings, we can try to visualize the embedding space to see if it makes sense. First, we can take any word in the space and check its closest neighbors."
      ],
      "metadata": {
        "id": "O3oE-tpR7I39"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "lab_util.show_similar_words(vectorizer.tokenizer, reps_word2vec, show_tokens)"
      ],
      "outputs": [],
      "metadata": {
        "id": "yMW4QND56bHF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also cluster the embedding space. Clustering in 4 or more dimensions is hard to visualize, and even clustering in 2 or 3 can be difficult because there are so many words in the vocabulary. One thing we can try to do is assign cluster labels and qualitiatively look for an underlying pattern in the clusters."
      ],
      "metadata": {
        "id": "ue-9CPSc7fi9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "indices = KMeans(n_clusters=10).fit_predict(reps_word2vec)\n",
        "zipped = list(zip(range(vectorizer.tokenizer.vocab_size), indices))\n",
        "np.random.shuffle(zipped)\n",
        "zipped = zipped[:100]\n",
        "zipped = sorted(zipped, key=lambda x: x[1], reverse=True)\n",
        "for token, cluster_idx in zipped:\n",
        "    word = vectorizer.tokenizer.token_to_word[token]\n",
        "    print(f\"{word}: {cluster_idx}\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "v-Yf6NMCXVx4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we can use the trained word embeddings to construct vector representations of full reviews. One common approach is to simply average all the word embeddings in the review to create an overall embedding. Implement the transform function in Word2VecFeaturizer to do this."
      ],
      "metadata": {
        "id": "ci1TkENU78Wn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def w2v_featurizer(xs):\n",
        "    # This function takes in a matrix in which each row contains the word counts\n",
        "    # for the given review. It should return a matrix in which each row contains\n",
        "    # the average Word2Vec embedding of each review (hint: this will be very\n",
        "    # similar to `lsa_featurizer` from above, just using Word2Vec embeddings \n",
        "    # instead of LSA).\n",
        "\n",
        "    feats = None # Your code here!\n",
        "\n",
        "    # normalize\n",
        "    return feats / np.sqrt((feats ** 2).sum(axis=1, keepdims=True))\n",
        "\n",
        "training_experiment(\"word2vec\", w2v_featurizer, 3000)\n",
        "print()"
      ],
      "outputs": [],
      "metadata": {
        "id": "A5vjmRV6Dgbu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 2: Lab writeup**\n",
        "\n",
        "Part 2 of your lab report should discuss any implementation details that were important to filling out the code above, as well as your answers to the questions in Part 2 of the Homework 2 handout. Below, you can set up and perform experiments that answer these questions (include figures, plots, and tables in your write-up as you see fit)."
      ],
      "metadata": {
        "id": "XSfoQbxaXtfH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiments for Part 2"
      ],
      "metadata": {
        "id": "Beb7dgqWycYx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Your code here!"
      ],
      "outputs": [],
      "metadata": {
        "id": "obr-zEmNydDm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3 (6.864 only)"
      ],
      "metadata": {
        "id": "5_HYOLQd5JLx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Part 3, you will extend the methods you've implemented in Parts 1 and 2 with the goal of improving final predictive performance. You should experiment with at least one idea to improve the model --- feel free to focus on either the featurizer or the classifier. Some suggestions of things you could try:\n",
        "\n",
        "1. Implement a different TD matrix normalization method (see lecture slides for alternatives to TF-IDF).\n",
        "2. Implement a different Word2Vec formulation (in Part 2, you implemented the CBOW formulation; does the skip-gram formulation perform any better?).\n",
        "3. Implement a more sophisticated classifier module.\n",
        "4. Tune featurizer and/or classifier hyperparameters (for full marks, you should obtain at least a 1% improvement in prediction accuracy if you only tune hyperparameters).\n",
        "\n",
        "In your report, discuss what you implemented (including relevant design decisions), and how your change(s) impacted performance.\n",
        "\n",
        "Note: As long as you try something with difficulty comparable to the suggested modifications and have a meaningful discussion of your results in your report, you can earn full marks (you do not necessarily need to improve performance)."
      ],
      "metadata": {
        "id": "70uuuHpr5NT4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Your code here!"
      ],
      "outputs": [],
      "metadata": {
        "id": "pTCrIkai-bkF"
      }
    }
  ]
}